{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c75c2b-1fa6-4085-a3e5-a8c131786a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Temii\\\\Downloads'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0690d-2a6d-4429-9b4a-2b2b0a5e9bb3",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "#### Pandas is a library to manipulate data. There is two data structures in pandas.\n",
    "### i)\tSeries  single column with single dtypes\n",
    "### ii)\tDataFrame  multiple columns with multiple datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee4a3-f2bb-41a9-907e-a7b7d20c36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = pd.Series([1,12,123,1234,12345])\n",
    "dict = pd.Series({'a':10,'b':20,'c':30})\n",
    "numpy_array = pd.Series(np.array([1,12,123,1234,12345]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d45de8-e097-4286-95fa-27e9008bce79",
   "metadata": {},
   "source": [
    "### Make a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d76e4-a79b-438e-827a-f914da4a4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = pd.DataFrame([[1,'zain'],[2,'asif'],[3,'temii']], columns=['ID','Name'])\n",
    "dict = pd.DataFrame({'id':[1,2,3],'name':['zain','asif','temii']})\n",
    "numpy_array = pd.DataFrame(np.array([[1,'zain'],[2,'asif'],[3,'temii']]), columns=['id','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddf0eee-e24c-4b20-a48d-99d23b64ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Make it Simple.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455c3ce-c3b5-4dc6-ac78-b4a268eed9a1",
   "metadata": {},
   "source": [
    "### Acces and change any value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58fcf0-cbf5-41e3-929d-189f60be7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'][1] ='value'                     # assign a new value\n",
    "df[col_index][row_idex] = 'new value'     # assign a new value\n",
    "df.index = [1,2,3,4]                      # change index\n",
    "df.index = ['1st','2nd','3rd','4th']      # change index\n",
    "df.set_index('col_name')                  # set any column to index\n",
    "df.reset_index()                          # reset index to default\n",
    "df.sort_index()                           # sort values by index\n",
    "df.sort_index(axis=1,ascending=False)     # sort by columns\n",
    "# axis =1 is for column and axis=0 is for row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba16244-6019-44a6-8ac9-7b3a1e837a24",
   "metadata": {},
   "source": [
    "### useful insgihts function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d6134-2d27-4c95-a003-c8736c205086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()      # head of df (first few rows)\n",
    "df.tail()      # tail of df (last few rows)\n",
    "df.info()      # summary of df (rows, columns, dtypes)\n",
    "df.describe()  # generate discriptive statistics (mean, std, min, 25%, 50%, 75%, max)\n",
    "df.shape       # return dimensions of df (rows, columns)\n",
    "df.columns     # Return columns name of DataFrame\n",
    "df.index       # range index (start=, stop=, step=)\n",
    "df.dtypes      # tell df types of columns\n",
    "df.nunique()   # return number of unique values in each column\n",
    "df.value_counts()     # give frequency of unique values in columns\n",
    "df.sample()           # random sample of rows from df frame \n",
    "df.memory_usage()     # memory usage of each column\n",
    "df.duplicated().sum() # check no of duplicate rows\n",
    "df.T                  # take a transpose of dfframe\n",
    "df['col'].astype('int')                       # change dtype of column\n",
    "df.select_dtypes(include='object')            # select columns on behalf of dtypes\n",
    "df.rename(columns = {'column_a': 'column_1'}) # rename your columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aedbc3-458e-4db8-8ee8-81ad4e5ab339",
   "metadata": {},
   "source": [
    "# STATISTICAL FUNCTIONS:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83ba8e-4f2b-48af-9c2c-8b71f2da2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_col'].mean()     # average\n",
    "df['num_col'].median()   # middle\n",
    "df['num_col'].mode()     # mode\n",
    "df['num_col'].std()      # standard deviation\n",
    "df['num_col'].var()      # variance\n",
    "df['num_col'].sum()      # total of values\n",
    "df['num_col'].min()      # minimun\n",
    "df['num_col'].max()      # maximun\n",
    "df['num_col'].corr()     # correlation\n",
    "df['num_col'].cov()      # co-variance\n",
    "df['num_col'].skew()     # skewness\n",
    "df['num_col'].kurt()     # kurtosis\n",
    "df['num_col'].cumsum()   # commulative sum\n",
    "df['num_col'].cumprod()  # commulative product\n",
    "df['num_col'].round(2)   # round at 2 integer\n",
    "df.count()               # count the rows for each columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c1026-9b04-4f1e-913a-c6cd4cbb213b",
   "metadata": {},
   "source": [
    "## DataFrame Indexing and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4689d6-b7fc-4595-9433-71c5e5b0444e",
   "metadata": {},
   "source": [
    "### Using loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc83cea-b412-4d5e-ac97-f06d4e744f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:2]                    # acess by rows index\n",
    "df.loc[1,'col']                # by row index and column name\n",
    "#     row   column\n",
    "df.loc[[1,2],['col1','col2']]  # access multiple row and column\n",
    "df.loc[1:3,'col1':'col3']      # acces by slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbb8ab-fece-4a3d-8f43-946dbe5b1b9f",
   "metadata": {},
   "source": [
    "### Using iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a307802-d7fb-48bd-842d-5f24eda536c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0,2],[0,2]]   # acess by both  of row and column inde\n",
    "#        row   column\n",
    "df.iloc[:,[1,2]]       # ALl rows but specific columns\n",
    "df.iloc [[0,2],:]      # get all columns but specific rows\n",
    "df.iloc[0:2,1:3]       # access rows and columns by slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c717de5-2833-4453-b489-4bc4aa02680c",
   "metadata": {},
   "source": [
    "### Selecting specific rows and columns by labels and postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0f32d-c7f9-4aeb-acf8-6535c2a01b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col']            # Access column\n",
    "df['col'][3]         # acess col with row index\n",
    "df[['col1','col2']]  # access multiple columns\n",
    "df.loc['row']        # get row by label\n",
    "df.iloc[1]           # get row by position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bb7a8-d2d1-42b1-b3e7-36f87f4dd23e",
   "metadata": {},
   "source": [
    "### Condition Based Selection or Filterring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4e425-a986-4be0-9c76-24896176b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['col']>60]                      # filter DatafFrame by condition\n",
    "df[(df['col']>2) and (df['col2']<6)]  # filter by 2 columns using and or\n",
    "df[(df['col']>2) & (df['col2']<6)]    # filter by 2 columns using & , |\n",
    "df['col'].isin(['value','value2'])    # filter values in column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef202d96-8142-40b1-aa7b-dbc0a840de25",
   "metadata": {},
   "source": [
    "### Boolean and Fancy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea46918-52cd-4252-81ee-1d4db6dd9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have operators  ==, >, <, <=, >=, &, |\n",
    "df[df['col']>= 4]     # Boolean\n",
    "df.loc[[2:6,'col']]   # Fancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1374ea46-8233-4f40-800e-f7783f8c4a15",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7168e6-ee71-48b6-b56d-1a730131c802",
   "metadata": {},
   "source": [
    "### i) Identify Missing values   (NaN , Nan , None, Null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2afdd1-625b-421c-9cbe-46577e8e0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()         # check null values true or False\n",
    "df.notnull()        # same as above\n",
    "df.isna()           # same as above\n",
    "df.isnull().sum()   # missing values counts \n",
    "df.isnull().mean()  # missing value % count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3474381d-8809-4201-9715-31a052ba6554",
   "metadata": {},
   "source": [
    "### ii) Dropping missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b858a-8f21-4498-ad73-25400a4cb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('row_index')             # drop specfic row by index\n",
    "df.drop(['row'])                 # drop multiple rows\n",
    "df.drop([1:3])                   # drop multiple rows by slicing\n",
    "df.drop(['col'],axis=1)          # drop column if axis=1\n",
    "df.drop(['col1','col2'], axis=1) # drop multiple columns\n",
    "df.drop(['col1','col2'], axis=1, inplace=True) # inplace=True used for save changes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0e5a7-1066-467f-b2a9-55b958c9a9c5",
   "metadata": {},
   "source": [
    "### Dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe5141-356e-4ba8-a7eb-3ec146a2d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()                 # drop all null values\n",
    "df.dropna(how='any')        # drop rows with any missing values \n",
    "df.drona(how='all')         # drop all null values\n",
    "df.dropna(subset=['col'])   # drop null values from specific column\n",
    "df.dropna(thresh=3)         # drop rows with fewer than 3 null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76935083-39e0-4dfd-905a-2c2d6a78bfe9",
   "metadata": {},
   "source": [
    "### iii) Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef37e2-60f9-448e-a989-7fe04e5e8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('value')         # fill null with value  \n",
    "df.fillna(method='ffill')  # fill rows by forward filling\n",
    "df.fillna(method='bfill')  # fill rows by backward filling\n",
    "df.fillna(method='ffill', axis=1)  # fill column by forward filling\n",
    "df.fillna(method='bfill',axis=1)   # fill column by backward filling\n",
    "df.fillna('value',inplace=True,limit=3)     # inplace for save changes, limit for max replacement\n",
    "df.fillna({'col1':'value','col2':'value'})  # fill null specific column with specific value\n",
    "df.fillna(df['col'].mean(), inplace=True)   # fill numerical values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cab065-9645-47d7-a56e-c1cf8b32540b",
   "metadata": {},
   "source": [
    "## Data Manipulation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0749e-22d5-4856-b16a-ffe9e6538331",
   "metadata": {},
   "source": [
    "#### Re-naming columns and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891c7d2-cb97-4eea-ac07-d13278a21f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'old':'new'})    # rename column\n",
    "df.rename(index={0:'1st',1:'2nd'})  # rename  index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f303c4b-dfba-4ce7-9804-3e923aebc231",
   "metadata": {},
   "source": [
    "#### Re-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc795c-3562-48f0-a253-17020aeb75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex([2,3,4,5])                   # re order index\n",
    "df.set_index('col',inplace=True)        # set specific column as index\n",
    "df.reset_index(drop=True, inplace=True) # reset default index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040c3e8-f266-4b2d-817c-f46637a68665",
   "metadata": {},
   "source": [
    "#### Rename Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aea2d8-30fa-4604-87bd-6e3e71de2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()                            # drop all the duplicate rows\n",
    "df.drop_duplicates(subset=['col'],keep='first') # keep only 1st duplicate rows\n",
    "df.drop_duplicates(subset=['col'],keep='last') # keep only last duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a4935-fd16-467b-91db-e448e775653d",
   "metadata": {},
   "source": [
    "### Replace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc1751-c333-489c-85ad-472578af5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('old','new')                                 # replace old value with new\n",
    "df.replace({'old1':'new1','old2':'new2'})               # replace multiple values\n",
    "df.replace({'col':{'old':'old'},'col2':{'old':'new'}})  # replace values in specific column\n",
    "df.replace(['old1','old2'],['new1','new2'])             # repalce values using list\n",
    "df.replace(1,method='ffill')           # replace using forward filling\n",
    "df.replace(1,method='bfill')           # replace using backward filling\n",
    "df.replace(1,method='bfill',limit=3)   # repalce with impose limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650ab94-d6bc-4f81-9414-db850ea213d9",
   "metadata": {},
   "source": [
    "#### Replace using Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39946db3-b4ac-4d18-974e-dbbd74284cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all the A-Z and 0-9 and a-z \n",
    "df.replace({'col':'[A-Za-z0-9]'},'value', regex=True)           \n",
    "df.replace(to_replace=r'.regular expression or old_word',value='new_value', regex=True)\n",
    "df.str.replace(r'\\W')  # remove special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06e60b-a5ed-4a73-90cb-04d8e8b1bede",
   "metadata": {},
   "source": [
    "## Commonly Used Regular Expressions in Pandas Replace Function\r\n",
    "###### 1. Basic Matching\r\n",
    "- `r'\\d'`: Matches any digit (0-9).\r\n",
    "- `r'\\D'`: Matches any non-digit character.\r\n",
    "- `r'\\s'`: Matches any whitespace (space, tab, newline).\r\n",
    "- `r'\\S'`: Matches any non-whitespace charac####r.\r\n",
    "\r\n",
    "## 2. Anchors\r\n",
    "- `r'^pattern'`: Matches strings starting with \"pattern\".\r\n",
    "- `r'pattern$'`: Matches strings ending with \"p####tern\".\r\n",
    "\r\n",
    "## 3. Repetition\r\n",
    "- `r'a+'`: Matches one or more occurrences of \"a\".\r\n",
    "- `r'a*'`: Matches zero or more occurre####es of \"a\".\r\n",
    "\r\n",
    "## 4. Groups and Alternation\r\n",
    "- `r'(a|b)'`: Matches \"a\" or \"b\".\r\n",
    "- `r'(abc)'`: Matches the exa#c#t group \"abc\".\r\n",
    "\r\n",
    "## 5. SpeciaW ChaRemove speical charactershes a literal period.\r\n",
    "- `r'\\$'`: Matches a li##teral dollar sign.\r\n",
    "\r\n",
    "## 6. Character Classes\r\n",
    "- `r'[aeiou]'`: Matches any one of the specified characters.\r\n",
    "- `r'[^aeiou]'`: Matches any character except the specified ones.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abdc2f-c447-4d7a-b81a-b07450a9975e",
   "metadata": {},
   "source": [
    "## Applying Custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293f12b-ba38-4241-b425-02fbd918a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].apply(lambda x:x**2)                 #apply custom power function to specific column\n",
    "df.applymap(lambda x:x*2)                      # apply function on DataFrame\n",
    "df.apply(lambda row: row['A']+row['B'], axis=1)# apply function on column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d578328-0981-4121-8c78-bfab6d30eb39",
   "metadata": {},
   "source": [
    "### Removing leading and trailing   strip(), lstrip(), rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3587bc-7e5d-4f4f-9703-8e44dd2a403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting strings\n",
    "df['col'].str.split('delimiter',expand=True)\n",
    "# delimeter are (, . - / etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da43e88-6cee-4a71-9251-3841a77a31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].str.strip('123./_ word')      # remove special char from column with regex\n",
    "df['col'].str.lstrip('delimiter')       # remove from left\n",
    "df['col'].str.rstrip('delimiter')       # remve from right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18f145-7f0a-4574-b94f-e5c7536a765b",
   "metadata": {},
   "source": [
    "## Merge , Joining and concating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd1dcb8-23ec-4a44-a975-4cb2f1462bb2",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50ae6d-593c-4a1c-ba89-2a121ef3bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2)                      # merge two DataFrame\n",
    "pd.merge(df1,df2, on='same key col')   # merge on same key col\n",
    "pd.merge(df1,df2, how ='inner')        # only matching column\n",
    "pd.merge(df1,df2, how ='outer')        # all the columns merge\n",
    "pd.merge(df1,df2, how ='left')         # all from left df\n",
    "pd.merge(df1,df2, how ='right')        # all from right df\n",
    "pd.merge(df1,df2, indicator=True)      # used for indiction of data which is df1 or df2\n",
    "pd.merge(df1,df2,left_index=True )     # left_index = True mean it belongs to left df\n",
    "pd.merge(df1,df2,right_index=True )    # right_index = True mean it belongs to right df\n",
    "pd.merge(df1,df2,suffixes=('left'))    # we can name the left DF\n",
    "pd.merge(df1,df2,suffixes=('right'))    # we can name the right DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5e174-ad96-4492-877e-9d90ea39fd36",
   "metadata": {},
   "source": [
    "#### Join   - join is same as like merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691992e2-7c64-4954-9e45-28a54cc62994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join(df2, how='left', on='key',lsuffix='left_df_name',\n",
    "        rsuffix='right_df_name',sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5355e-f2f1-451c-8367-6c595e983966",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544a33f-aa4e-4fd5-b001-5f0601cc2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([sr1,sr2])\n",
    "pd.concat([df1,df2])\n",
    "pd.concat([df1,df2],axis =1,join='inner',ignore_index=True,keys=['1st_df','2nd_df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c07632-fe80-4f88-b242-ecd34e6b29af",
   "metadata": {},
   "source": [
    "## Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0dbd4-0604-46b2-86cf-cc590fa3e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('col')['value_column'].sum()\n",
    "df.get('item_name')  # get certain item data\n",
    "df.agg({'col1':'sum','col2':'mean'})   # aggrate of specific column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5986326-6a53-4dd2-9683-144d2f4bbcf4",
   "metadata": {},
   "source": [
    "## Pivoting and Reshaping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8647b8e1-4c25-4956-a28f-85b21b5a6d8a",
   "metadata": {},
   "source": [
    "### Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f82f76-f21e-4da4-adcb-337eb9bd8b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index='index_col',columns='col',values='numeric_col')\n",
    "df.pivot_table(index='category',values='values',aggfunc='sum')\n",
    "df.pivot_table(index='col for row',columns='col for column',values='values',aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23238510-e3ff-47c3-b736-dce67139db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.melt(id_vars='Month').to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eadd1ac-769c-4878-828d-b70c7b94f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb482a-62cc-42f4-ac35-17feedb71c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
